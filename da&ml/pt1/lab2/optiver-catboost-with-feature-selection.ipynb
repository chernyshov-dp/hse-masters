{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-18T18:17:57.721027Z",
     "iopub.status.busy": "2023-12-18T18:17:57.720774Z",
     "iopub.status.idle": "2023-12-18T18:17:58.077175Z",
     "shell.execute_reply": "2023-12-18T18:17:58.076286Z",
     "shell.execute_reply.started": "2023-12-18T18:17:57.721001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/d/daniilchernyshov/optiver-trading-at-the-close/train.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/public_timeseries_testing_util.py\n",
      "/kaggle/input/optiver-trading-at-the-close/train.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/example_test_files/sample_submission.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/optiver2023/competition.cpython-310-x86_64-linux-gnu.so\n",
      "/kaggle/input/optiver-trading-at-the-close/optiver2023/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:07:47.352542Z",
     "iopub.status.busy": "2023-12-05T19:07:47.352173Z",
     "iopub.status.idle": "2023-12-05T19:07:49.739804Z",
     "shell.execute_reply": "2023-12-05T19:07:49.739025Z",
     "shell.execute_reply.started": "2023-12-05T19:07:47.352516Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from numba import njit, prange\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import EShapCalcType, EFeaturesSelectionAlgorithm\n",
    "from catboost import Pool\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T18:18:25.435623Z",
     "iopub.status.busy": "2023-12-18T18:18:25.434551Z",
     "iopub.status.idle": "2023-12-18T18:18:43.726382Z",
     "shell.execute_reply": "2023-12-18T18:18:43.725506Z",
     "shell.execute_reply.started": "2023-12-18T18:18:25.435585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n",
    "\n",
    "features = [col for col in train.columns if col not in ['row_id', 'time_id', 'target']]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:02.311698Z",
     "iopub.status.busy": "2023-12-05T19:08:02.311402Z",
     "iopub.status.idle": "2023-12-05T19:08:02.690472Z",
     "shell.execute_reply": "2023-12-05T19:08:02.689598Z",
     "shell.execute_reply.started": "2023-12-05T19:08:02.311674Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.dropna(subset=[\"target\"])\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:02.691965Z",
     "iopub.status.busy": "2023-12-05T19:08:02.691638Z",
     "iopub.status.idle": "2023-12-05T19:08:03.061212Z",
     "shell.execute_reply": "2023-12-05T19:08:03.06038Z",
     "shell.execute_reply.started": "2023-12-05T19:08:02.691937Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train[features].copy(deep=True)\n",
    "y = train['target'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Full Process or Do Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a trigger to run the full feature selection and hyperparam tuning process or to simply make you make your final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.062758Z",
     "iopub.status.busy": "2023-12-05T19:08:03.062388Z",
     "iopub.status.idle": "2023-12-05T19:08:03.067067Z",
     "shell.execute_reply": "2023-12-05T19:08:03.066146Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.062722Z"
    }
   },
   "outputs": [],
   "source": [
    "submit = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.069057Z",
     "iopub.status.busy": "2023-12-05T19:08:03.068559Z",
     "iopub.status.idle": "2023-12-05T19:08:03.084041Z",
     "shell.execute_reply": "2023-12-05T19:08:03.083144Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.069023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute triplet imbalance in parallel using Numba\n",
    "@njit(parallel=True)\n",
    "def compute_triplet_imbalance(df_values, comb_indices):\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(comb_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "\n",
    "    # Loop through all combinations of triplets\n",
    "    for i in prange(num_combinations):\n",
    "        a, b, c = comb_indices[i]\n",
    "\n",
    "        # Loop through rows of the DataFrame\n",
    "        for j in range(num_rows):\n",
    "            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "\n",
    "            # Prevent division by zero\n",
    "            if mid_val == min_val:\n",
    "                imbalance_features[j, i] = np.nan\n",
    "            else:\n",
    "                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "\n",
    "    return imbalance_features\n",
    "\n",
    "\n",
    "# Function to calculate triplet imbalance for given price data and a DataFrame\n",
    "def calculate_triplet_imbalance_numba(price, df):\n",
    "    # Convert DataFrame to numpy array for Numba compatibility\n",
    "    df_values = df[price].values\n",
    "    comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n",
    "\n",
    "    # Calculate the triplet imbalance using the Numba-optimized function\n",
    "    features_array = compute_triplet_imbalance(df_values, comb_indices)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def numba_imb_features(df):\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "\n",
    "    # Calculate triplet imbalance features using the Numba-optimized function\n",
    "    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(X):\n",
    "\n",
    "    _X = X.copy()\n",
    "\n",
    "    # features taken from https://www.kaggle.com/code/zulqarnainali/explained-singel-model-optiver\n",
    "    # market_urgency', 'seconds_in_bucket', 'liquidity_imbalance', 'imbalance_momentum', 'price_spread', 'matched_imbalance', 'bid_size', 'matched_size', 'spread_intensity', 'ask_size'\n",
    "    _X[\"volume\"] = _X.eval(\"ask_size + bid_size\")\n",
    "    _X[\"mid_price\"] = _X.eval(\"(ask_price + bid_price) / 2\")\n",
    "    _X[\"liquidity_imbalance\"] = _X.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    _X[\"matched_imbalance\"] = _X.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n",
    "    _X[\"size_imbalance\"] = _X.eval(\"bid_size / ask_size\")\n",
    "\n",
    "    _X[\"imbalance_momentum\"] = _X.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / _X['matched_size']\n",
    "    _X[\"price_spread\"] = _X[\"ask_price\"] - _X[\"bid_price\"]\n",
    "    _X[\"spread_intensity\"] = _X.groupby(['stock_id'])['price_spread'].diff()\n",
    "    _X['price_pressure'] = _X['imbalance_size'] * (_X['ask_price'] - _X['bid_price'])\n",
    "    _X['market_urgency'] = _X['price_spread'] * _X['liquidity_imbalance']\n",
    "    _X['depth_pressure'] = (_X['ask_size'] - _X['bid_size']) * (_X['far_price'] - _X['near_price'])\n",
    "\n",
    "    _X[\"dow\"] = _X[\"date_id\"] % 5  # Day of the week\n",
    "    _X[\"seconds\"] = _X[\"seconds_in_bucket\"] % 60  # Seconds\n",
    "    _X[\"minute\"] = _X[\"seconds_in_bucket\"] // 60  # Minutes\n",
    "\n",
    "    # # Calculate shifted and return features for specific columns\n",
    "    for col in ['matched_size', 'imbalance_size', 'reference_price']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            _X[f\"{col}_shift_{window}\"] = _X.groupby('stock_id')[col].shift(window)\n",
    "            _X[f\"{col}_ret_{window}\"] = _X.groupby('stock_id')[col].pct_change(window)\n",
    "\n",
    "    # # Calculate diff features for specific columns\n",
    "    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            _X[f\"{col}_diff_{window}\"] = _X.groupby(\"stock_id\")[col].diff(window)\n",
    "\n",
    "    # Create features for pairwise price imbalances\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    for c in combinations(prices, 2):\n",
    "        _X[f\"{c[0]}_{c[1]}_imb\"] = _X.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "\n",
    "    # Generate imbalance features\n",
    "    _X = numba_imb_features(_X)\n",
    "\n",
    "    _X = _X.replace([np.inf, -np.inf], 0)\n",
    "    _X.drop(columns=['date_id'], inplace=True)\n",
    "\n",
    "    return _X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.101846Z",
     "iopub.status.busy": "2023-12-05T19:08:03.101504Z",
     "iopub.status.idle": "2023-12-05T19:08:03.113492Z",
     "shell.execute_reply": "2023-12-05T19:08:03.112655Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.101813Z"
    }
   },
   "outputs": [],
   "source": [
    "if not submit:\n",
    "    \n",
    "    number_of_days = len(X.date_id.unique()) # There are 481 trading days, we'll take the last n as testing set\n",
    "    testing_days = 10\n",
    "    training_days = number_of_days - testing_days\n",
    "    training_days, testing_days\n",
    "\n",
    "    # mask to grab the days for training and testing\n",
    "    training_mask = X.date_id <= training_days\n",
    "    testing_mask = X.date_id > training_days\n",
    "\n",
    "    # subset and make training and validation sets\n",
    "    X_train, X_val, y_train, y_val = X[training_mask], X[testing_mask], y[training_mask], y[testing_mask] #train_test_split(X, y, test_size=0.20, random_state=0, shuffle=True, stratify=X['stock_id']) # random_state=8\n",
    "    X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
    "    \n",
    "    # apply feature engineering\n",
    "    X_train = feature_engineering(X_train)\n",
    "    X_val = feature_engineering(X_val)\n",
    "\n",
    "    # Convert all numerics to float32 to reduce memory footprint\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_val = X_val.astype(np.float32)\n",
    "    \n",
    "    X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.117815Z",
     "iopub.status.busy": "2023-12-05T19:08:03.117531Z",
     "iopub.status.idle": "2023-12-05T19:08:03.129306Z",
     "shell.execute_reply": "2023-12-05T19:08:03.128356Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.117781Z"
    }
   },
   "outputs": [],
   "source": [
    "if not submit: \n",
    "    %%time\n",
    "    def select_features(model, algorithm, num_features, steps):\n",
    "\n",
    "        print('Algorithm:', algorithm)\n",
    "\n",
    "        summary = model.select_features(\n",
    "            train_pool,\n",
    "            eval_set=val_pool,\n",
    "            features_for_select=list(range(train_pool.num_col())),\n",
    "            num_features_to_select=num_features,\n",
    "            steps=steps,\n",
    "            algorithm=algorithm,\n",
    "            shap_calc_type=EShapCalcType.Regular,\n",
    "            train_final_model=True,\n",
    "            logging_level='Silent',\n",
    "            plot=True\n",
    "        )\n",
    "\n",
    "        print('Selected features:\\n', summary['selected_features_names'])\n",
    "        print('Eliminated features:\\n', summary['eliminated_features_names'])\n",
    "\n",
    "        return summary\n",
    "\n",
    "    train_pool = Pool(data=X_train, label=y_train)\n",
    "    val_pool = Pool(data=X_val, label=y_val)\n",
    "\n",
    "    # baseline parameters\n",
    "    params = dict(loss_function='MAE',\n",
    "                  eval_metric = 'MAE',\n",
    "                  metric_period=100,\n",
    "                  task_type='GPU',\n",
    "                  od_type='Iter',\n",
    "                  od_wait=50,\n",
    "                  bootstrap_type='Bernoulli',\n",
    "                  )\n",
    "\n",
    "    # run the feature selection algorithm\n",
    "    model = CatBoostRegressor(**params)\n",
    "    summary = select_features(model=model, algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues, num_features=50, steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.130945Z",
     "iopub.status.busy": "2023-12-05T19:08:03.130405Z",
     "iopub.status.idle": "2023-12-05T19:08:03.143287Z",
     "shell.execute_reply": "2023-12-05T19:08:03.142381Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.13092Z"
    }
   },
   "outputs": [],
   "source": [
    "# summary = {}\n",
    "# feature selection process turned off for submission\n",
    "# summary['selected_features_names'] = ['seconds_in_bucket', 'imbalance_buy_sell_flag', 'bid_size', 'ask_size', 'volume', \n",
    "#                                       'liquidity_imbalance', 'size_imbalance', 'imbalance_momentum', 'price_spread', 'spread_intensity', \n",
    "#                                       'market_urgency', 'minute', 'matched_size_ret_1', 'matched_size_shift_10', 'imbalance_size_ret_1', \n",
    "#                                       'imbalance_size_ret_2', 'imbalance_size_ret_3', 'imbalance_size_ret_10', 'ask_price_diff_2', \n",
    "#                                       'ask_price_diff_3', 'bid_price_diff_2', 'bid_price_diff_3', 'reference_price_near_price_imb', \n",
    "#                                       'reference_price_ask_price_imb', 'reference_price_bid_price_imb', 'reference_price_wap_imb', \n",
    "#                                       'far_price_ask_price_imb', 'far_price_bid_price_imb', 'far_price_wap_imb', 'near_price_ask_price_imb', \n",
    "#                                       'near_price_bid_price_imb', 'near_price_wap_imb', 'ask_price_bid_price_imb', 'ask_price_wap_imb', \n",
    "#                                       'bid_price_wap_imb', 'all_prices_mean', 'all_sizes_mean', 'all_prices_std', 'all_sizes_std', \n",
    "#                                       'all_prices_skew', 'all_sizes_skew', 'all_prices_kurt', 'all_sizes_kurt', 'ask_price_bid_price_wap_imb2', \n",
    "#                                       'ask_price_bid_price_reference_price_imb2', 'ask_price_wap_reference_price_imb2', 'bid_price_wap_reference_price_imb2', \n",
    "#                                       'matched_size_bid_size_ask_size_imb2', 'matched_size_bid_size_imbalance_size_imb2', 'matched_size_ask_size_imbalance_size_imb2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.144669Z",
     "iopub.status.busy": "2023-12-05T19:08:03.144404Z",
     "iopub.status.idle": "2023-12-05T19:08:03.156306Z",
     "shell.execute_reply": "2023-12-05T19:08:03.155262Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.144646Z"
    }
   },
   "outputs": [],
   "source": [
    "if not submit:\n",
    "    \n",
    "    %%time\n",
    "\n",
    "    # https://medium.com/analytics-vidhya/catboost-101-fb2fdc3398f3\n",
    "\n",
    "    # Retrain the model with the recommended number of iterations and the reduced feature set\n",
    "    final_params = params.copy()\n",
    "    final_params[\"iterations\"] = model.best_iteration_\n",
    "    print(final_params)\n",
    "\n",
    "    # fit the final model\n",
    "    final_model = CatBoostRegressor(**final_params)\n",
    "    final_model.fit(X_train[summary['selected_features_names']], y_train)\n",
    "\n",
    "    # predict with the final model\n",
    "    y_val_pred = final_model.predict(X_val[summary['selected_features_names']])\n",
    "\n",
    "    # get the validation set score\n",
    "    y_val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    print(f\"MAE on validation set: {y_val_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.157596Z",
     "iopub.status.busy": "2023-12-05T19:08:03.157333Z",
     "iopub.status.idle": "2023-12-05T19:08:03.170445Z",
     "shell.execute_reply": "2023-12-05T19:08:03.169643Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.157574Z"
    }
   },
   "outputs": [],
   "source": [
    "if not submit:\n",
    "    \n",
    "    %%time\n",
    "    \n",
    "    # Retrain the model with the recommended number of iterations and the reduced feature set\n",
    "    exper_params = params.copy()\n",
    "    exper_params[\"iterations\"] = model.best_iteration_\n",
    "    print(exper_params)\n",
    "\n",
    "    # fit the experimental model\n",
    "    exper_model = CatBoostRegressor(**final_params)\n",
    "    exper_model.fit(X_train[summary['selected_features_names']], y_train)\n",
    "\n",
    "    # predict with the final model\n",
    "    y_val_pred = exper_model.predict(X_val[summary['selected_features_names']])\n",
    "\n",
    "    # get the validation set score\n",
    "    y_val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    print(f\"MAE on validation set: {y_val_mae}\")\n",
    "    \n",
    "    # get the feature importances and plot them\n",
    "    feat_importances = exper_model.get_feature_importance(prettified=True)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x=\"Importances\", y=\"Feature Id\", data=feat_importances[0:10])\n",
    "    plt.title('Top features:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold CV with selected features to find best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.172235Z",
     "iopub.status.busy": "2023-12-05T19:08:03.171597Z",
     "iopub.status.idle": "2023-12-05T19:08:03.179646Z",
     "shell.execute_reply": "2023-12-05T19:08:03.178897Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.172201Z"
    }
   },
   "outputs": [],
   "source": [
    "if not submit:\n",
    "    # 10-fold CV to find best hyperparameters\n",
    "    splitter = KFold(n_splits=10, shuffle=True)\n",
    "    splits = []\n",
    "    for i, (train_index, test_index) in enumerate(splitter.split(X_train, y_train)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        print(f\"  Train: index={train_index}, length={len(train_index)}\")\n",
    "        print(f\"  Test:  index={test_index},  length={len(test_index)}\")\n",
    "        splits.append((train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.181191Z",
     "iopub.status.busy": "2023-12-05T19:08:03.180839Z",
     "iopub.status.idle": "2023-12-05T19:08:03.193372Z",
     "shell.execute_reply": "2023-12-05T19:08:03.192404Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.18116Z"
    }
   },
   "outputs": [],
   "source": [
    "if not submit:\n",
    "    \n",
    "    %%time\n",
    "    \n",
    "    # baseline model\n",
    "    params = dict(loss_function='MAE',\n",
    "                  eval_metric = 'MAE',\n",
    "                  metric_period=100,\n",
    "                  task_type='GPU',\n",
    "                  od_type='Iter',\n",
    "                  od_wait=50,\n",
    "                  bootstrap_type='Bernoulli'\n",
    "                  )\n",
    "    model = CatBoostRegressor(**params)\n",
    "    \n",
    "    # search these params\n",
    "    param_distributions = {\"iterations\": [int(x) for x in np.linspace(start=200, stop=1000, num=15)],\n",
    "                           \"depth\": list(range(1, 16)),\n",
    "                           \"subsample\": loguniform(0.1, 1),\n",
    "                           \"random_strength\": np.linspace(start=1, stop=25, num=15),\n",
    "                           \"learning_rate\": loguniform(0.01, 1),\n",
    "                           \"l2_leaf_reg\": [int(x) for x in np.linspace(start=1, stop=40, num=20)],\n",
    "                           \"score_function\": ['L2', 'Cosine', 'NewtonL2', 'NewtonCosine']\n",
    "                          }\n",
    "    param_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.194611Z",
     "iopub.status.busy": "2023-12-05T19:08:03.194376Z",
     "iopub.status.idle": "2023-12-05T19:08:03.204229Z",
     "shell.execute_reply": "2023-12-05T19:08:03.203239Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.19459Z"
    }
   },
   "outputs": [],
   "source": [
    "if not submit:\n",
    "    \n",
    "    %%time\n",
    "\n",
    "    # HalvingRandomSearchCV\n",
    "    search_cv = HalvingRandomSearchCV(\n",
    "        model,\n",
    "        param_distributions=param_distributions,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv = splits,\n",
    "        n_candidates=200,\n",
    "        min_resources=100000,\n",
    "        max_resources=1000000,\n",
    "        random_state=7,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    search_cv.fit(X_train, y_train)\n",
    "    y_pred = search_cv.best_estimator_.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred) # 5.838548462599918 with 30 days validation data\n",
    "    print('Best search_cv score:' , search_cv.best_score_)\n",
    "    print('Validation set MAE: ', mae)\n",
    "    \n",
    "    columns = [f\"param_{name}\" for name in param_distributions.keys()]\n",
    "    columns += [\"mean_test_score\", \"std_test_score\"]\n",
    "    cv_results = pd.DataFrame(search_cv.cv_results_)\n",
    "    cv_results.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "    cv_results[columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.205446Z",
     "iopub.status.busy": "2023-12-05T19:08:03.205181Z",
     "iopub.status.idle": "2023-12-05T19:08:03.218897Z",
     "shell.execute_reply": "2023-12-05T19:08:03.218135Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.205413Z"
    }
   },
   "outputs": [],
   "source": [
    "if not submit: \n",
    "    search_cv.best_estimator_.get_params()\n",
    "# 'iterations': 771,\n",
    "#          'learning_rate': 0.6153054327622673,\n",
    "#          'depth': 13,\n",
    "#          'l2_leaf_reg': 9,\n",
    "#          'loss_function': 'MAE',\n",
    "#          'od_wait': 50,\n",
    "#          'od_type': 'Iter',\n",
    "#          'metric_period': 100,\n",
    "#          'random_strength': 4.428571428571429,\n",
    "#          'eval_metric': 'MAE',\n",
    "#          'task_type': 'GPU',\n",
    "#          'bootstrap_type': 'Bernoulli',\n",
    "#          'subsample': 0.9795657524290455,\n",
    "#          'score_function': 'Cosine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:03.220208Z",
     "iopub.status.busy": "2023-12-05T19:08:03.219926Z",
     "iopub.status.idle": "2023-12-05T19:08:49.527547Z",
     "shell.execute_reply": "2023-12-05T19:08:49.526521Z",
     "shell.execute_reply.started": "2023-12-05T19:08:03.220184Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply feature engineering\n",
    "X = feature_engineering(X)\n",
    "\n",
    "# Convert all numerics to float32 to reduce memory footprint\n",
    "X = X.astype(np.float32)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:08:49.528928Z",
     "iopub.status.busy": "2023-12-05T19:08:49.528612Z",
     "iopub.status.idle": "2023-12-05T19:08:49.53407Z",
     "shell.execute_reply": "2023-12-05T19:08:49.53304Z",
     "shell.execute_reply.started": "2023-12-05T19:08:49.528902Z"
    }
   },
   "outputs": [],
   "source": [
    "# selected_features = ['seconds_in_bucket', 'imbalance_buy_sell_flag', 'bid_size', 'ask_size', 'volume', 'liquidity_imbalance', \n",
    "#                      'size_imbalance', 'imbalance_momentum', 'price_spread', 'spread_intensity', 'market_urgency', 'minute', \n",
    "#                      'matched_size_ret_1', 'matched_size_shift_10', 'imbalance_size_ret_1', 'imbalance_size_ret_2', \n",
    "#                      'imbalance_size_ret_3', 'imbalance_size_ret_10', 'ask_price_diff_2', 'ask_price_diff_3', \n",
    "#                      'bid_price_diff_2', 'bid_price_diff_3', 'reference_price_near_price_imb', 'reference_price_ask_price_imb', \n",
    "#                      'reference_price_bid_price_imb', 'reference_price_wap_imb', 'far_price_ask_price_imb', 'far_price_bid_price_imb', \n",
    "#                      'far_price_wap_imb', 'near_price_ask_price_imb', 'near_price_bid_price_imb', 'near_price_wap_imb', 'ask_price_bid_price_imb', \n",
    "#                      'ask_price_wap_imb', 'bid_price_wap_imb', 'all_prices_mean', 'all_sizes_mean', 'all_prices_std', 'all_sizes_std', \n",
    "#                      'all_prices_skew', 'all_sizes_skew', 'all_prices_kurt', 'all_sizes_kurt', 'ask_price_bid_price_wap_imb2', \n",
    "#                      'ask_price_bid_price_reference_price_imb2', 'ask_price_wap_reference_price_imb2', 'bid_price_wap_reference_price_imb2', \n",
    "#                      'matched_size_bid_size_ask_size_imb2', 'matched_size_bid_size_imbalance_size_imb2', 'matched_size_ask_size_imbalance_size_imb2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:10:19.982047Z",
     "iopub.status.busy": "2023-12-05T19:10:19.980985Z",
     "iopub.status.idle": "2023-12-05T19:10:19.988729Z",
     "shell.execute_reply": "2023-12-05T19:10:19.987568Z",
     "shell.execute_reply.started": "2023-12-05T19:10:19.982001Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = X[selected_features]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:10:21.95051Z",
     "iopub.status.busy": "2023-12-05T19:10:21.95013Z",
     "iopub.status.idle": "2023-12-05T19:13:23.319345Z",
     "shell.execute_reply": "2023-12-05T19:13:23.318421Z",
     "shell.execute_reply.started": "2023-12-05T19:10:21.950481Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {'iterations': 771,\n",
    "         'learning_rate': 0.6153054327622673,\n",
    "         'depth': 13,\n",
    "         'l2_leaf_reg': 9,\n",
    "         'loss_function': 'MAE',\n",
    "         'od_wait': 50,\n",
    "         'od_type': 'Iter',\n",
    "         'metric_period': 100,\n",
    "         'random_strength': 4.428571428571429,\n",
    "         'eval_metric': 'MAE',\n",
    "         'task_type': 'GPU',\n",
    "         'bootstrap_type': 'Bernoulli',\n",
    "         'subsample': 0.9795657524290455,\n",
    "         'score_function': 'Cosine'}\n",
    "\n",
    "final_model = CatBoostRegressor(**params)\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:13:23.321708Z",
     "iopub.status.busy": "2023-12-05T19:13:23.321184Z",
     "iopub.status.idle": "2023-12-05T19:13:24.429576Z",
     "shell.execute_reply": "2023-12-05T19:13:24.428618Z",
     "shell.execute_reply.started": "2023-12-05T19:13:23.321676Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_importances = final_model.get_feature_importance(prettified=True)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x=\"Importances\", y=\"Feature Id\", data=feat_importances[0:10])\n",
    "plt.title('Top features:');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:13:24.431105Z",
     "iopub.status.busy": "2023-12-05T19:13:24.430702Z",
     "iopub.status.idle": "2023-12-05T19:13:24.441119Z",
     "shell.execute_reply": "2023-12-05T19:13:24.440176Z",
     "shell.execute_reply.started": "2023-12-05T19:13:24.431052Z"
    }
   },
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:13:24.443787Z",
     "iopub.status.busy": "2023-12-05T19:13:24.443513Z",
     "iopub.status.idle": "2023-12-05T19:13:24.448706Z",
     "shell.execute_reply": "2023-12-05T19:13:24.447754Z",
     "shell.execute_reply.started": "2023-12-05T19:13:24.443763Z"
    }
   },
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices) / np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:13:24.450224Z",
     "iopub.status.busy": "2023-12-05T19:13:24.449901Z",
     "iopub.status.idle": "2023-12-05T19:14:26.126465Z",
     "shell.execute_reply": "2023-12-05T19:14:26.125621Z",
     "shell.execute_reply.started": "2023-12-05T19:13:24.450198Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "y_min, y_max = -64, 64\n",
    "predictions = []\n",
    "cache = pd.DataFrame()\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    \n",
    "    cache = pd.concat([cache, test], ignore_index=True, axis=0)\n",
    "    if counter > 0:\n",
    "        cache = cache.groupby(['stock_id']).tail(21).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n",
    "    X_test = cache[features]\n",
    "    X_test = feature_engineering(X_test)[-len(test):]\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    preds = final_model.predict(X_test)\n",
    "    preds = zero_sum(preds, test['bid_size'] + test['ask_size'])\n",
    "    preds = np.clip(preds, y_min, y_max)\n",
    "    sample_prediction['target'] = preds\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:14:26.127884Z",
     "iopub.status.busy": "2023-12-05T19:14:26.127595Z",
     "iopub.status.idle": "2023-12-05T19:14:26.55558Z",
     "shell.execute_reply": "2023-12-05T19:14:26.554638Z",
     "shell.execute_reply.started": "2023-12-05T19:14:26.127858Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_prediction.hist(column='target', bins=100, range=[-10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T19:14:26.557176Z",
     "iopub.status.busy": "2023-12-05T19:14:26.556839Z",
     "iopub.status.idle": "2023-12-05T19:14:26.564281Z",
     "shell.execute_reply": "2023-12-05T19:14:26.563312Z",
     "shell.execute_reply.started": "2023-12-05T19:14:26.557149Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_prediction.to_csv('preds.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    },
    {
     "datasetId": 4187449,
     "sourceId": 7231841,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
